{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:06:20.084577Z",
     "start_time": "2025-07-02T10:06:20.079296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_dyn_v3.py\n",
    "\"\"\"Train *from scratch* the v3 dynamics model for the new scenario\n",
    "(two‑lap drift + recovery).  Works with the augmented dataset that already\n",
    "contains `gas` and `is_drift`.\n",
    "\n",
    "Usage (from repo root):\n",
    "\n",
    "```bash\n",
    "python train_dyn_v3.py  data/*.csv   \\\n",
    "                       --epochs 300  \\\n",
    "                       --batch 2048  \\\n",
    "                       --out dyn_v3.pt\n",
    "```\n",
    "\n",
    "Outputs:\n",
    "    • NPZ file  (X, Y, mu*, sig*)\n",
    "    • PyTorch checkpoint  dyn_v3.pt  (weights + μ/σ)\n",
    "\n",
    "The model maps  (yawRate, ay_world, beta, speed, a_steer, a_gas)\n",
    "            to  Δ(state)  for the next 20‑ms tick.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import argparse, sys, math\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import glob, json, math, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "\n"
   ],
   "id": "1b052fff01a12151",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:06:20.799045Z",
     "start_time": "2025-07-02T10:06:20.792044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# 1. CLI\n",
    "################################################################################\n",
    "\n",
    "CSV_GLOB   = \"../new_data/circle/*.csv\"   # could be list [\"file1.csv\", \"file2.csv\"]\n",
    "EPOCHS     = 300\n",
    "BATCH_SIZE = 2048\n",
    "OUT_MODEL  = \"dyn_v3.pt\"\n",
    "OUT_NPZ    = \"model_dataset_v3.npz\"\n"
   ],
   "id": "68e0538618b426d1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:06:21.294556Z",
     "start_time": "2025-07-02T10:06:21.273035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# 2. Feature engineering helpers\n",
    "################################################################################\n",
    "STEER_MIN, STEER_MAX = 1968, 4004\n",
    "GAS_MIN,   GAS_MAX   = 2886, 4002 \n",
    "STEER_C, STEER_SP = (STEER_MIN+STEER_MAX)/2, (STEER_MAX-STEER_MIN)/2\n",
    "GAS_C,   GAS_SP   = (GAS_MIN+GAS_MAX)/2,   (GAS_MAX-GAS_MIN)/2\n",
    "\n",
    "# PD‐like helper for numeric stability\n",
    "EPS = 1e-6\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add beta, speed, action normalisation.\"\"\"\n",
    "    # velocity components (m/s)   — 20‑ms delta\n",
    "    dt = df[\"t_sec\"].diff().fillna(0.02)\n",
    "    df[\"vx\"] = df[\"x_world\"].diff() / dt\n",
    "    df[\"vy\"] = df[\"y_world\"].diff() / dt\n",
    "    df[\"speed\"] = np.hypot(df[\"vx\"], df[\"vy\"])\n",
    "    # beta = angle between velocity vector and yaw\n",
    "    vel_ang = np.arctan2(df[\"vy\"], df[\"vx\"])\n",
    "    df[\"beta\"] = (vel_ang - df[\"yaw_rad\"] + np.pi) % (2*np.pi) - np.pi   # wrap to [-π,π]\n",
    "    # normalised actions\n",
    "    df[\"a_steer\"] = (df[\"steer\"] - STEER_C) / STEER_SP\n",
    "    df[\"a_gas\"]   = (df[\"gas\"]   - GAS_C)   / GAS_SP\n",
    "    return df\n",
    "\n",
    "def load_all(csv_glob: str) -> pd.DataFrame:\n",
    "    files = [Path(f) for f in glob.glob(csv_glob)]\n",
    "    if not files:\n",
    "        sys.exit(f\"No CSVs matched {csv_glob!r}\")\n",
    "    print(f\"Found {len(files)} CSV files\")\n",
    "    return pd.concat((pd.read_csv(f) for f in files), ignore_index=True)\n",
    "\n",
    "# world‑frame speed and beta\n",
    "def add_speed_beta(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    vx = df[\"x_world\"].diff() / df[\"t_sec\"].diff()\n",
    "    vy = df[\"y_world\"].diff() / df[\"t_sec\"].diff()\n",
    "    df[\"vx\"], df[\"vy\"] = vx, vy\n",
    "    df[\"speed\"] = np.hypot(vx, vy)\n",
    "    df[\"beta\"]  = np.arctan2(vy, vx) - df[\"yaw_rad\"]\n",
    "    return df.dropna().reset_index(drop=True)\n",
    "\n",
    "def build_matrices(df: pd.DataFrame):\n",
    "    # state s_t\n",
    "    S = df[[\"yawRate\", \"ay_world\", \"beta\", \"speed\"]].values.astype(np.float32)\n",
    "    # actions\n",
    "    a_steer = ((df[\"steer\"]-STEER_C)/STEER_SP).values.astype(np.float32)\n",
    "    a_gas   = ((df[\"gas\"]  -GAS_C)/GAS_SP  ).values.astype(np.float32)\n",
    "    A = np.stack([a_steer, a_gas], axis=1)\n",
    "    # drop last row to align with s_{t+1}\n",
    "    S, A = S[:-1], A[:-1]\n",
    "    Sn   = df[[\"yawRate\", \"ay_world\", \"beta\", \"speed\"]].values.astype(np.float32)[1:]\n",
    "    dS   = Sn - S\n",
    "    X    = np.hstack([S, A])\n",
    "    return X, dS\n"
   ],
   "id": "f0552224591ffdb9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:06:21.874668Z",
     "start_time": "2025-07-02T10:06:21.869350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# 3. Neural net definition\n",
    "################################################################################\n",
    "class DynNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(6, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "ebf130a0f7fdcb85",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:06:31.813487Z",
     "start_time": "2025-07-02T10:06:22.635345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# 4. Main training routine\n",
    "################################################################################\n",
    "print(\"\\n>>> Loading CSVs …\")\n",
    "df_raw = load_all(CSV_GLOB)\n",
    "print(\">>> Feature engineering …\")\n",
    "df = add_speed_beta(df_raw.copy())\n",
    "X, Y = build_matrices(df)\n",
    "print(f\"Dataset  X: {X.shape},  Y: {Y.shape}\")\n",
    "\n",
    "# Normalise\n",
    "mu_X, sig_X = X.mean(0), X.std(0)+1e-6\n",
    "mu_Y, sig_Y = Y.mean(0), Y.std(0)+1e-6\n",
    "Xn = (X - mu_X) / sig_X\n",
    "Yn = (Y - mu_Y) / sig_Y\n",
    "\n",
    "np.savez(OUT_NPZ, X=Xn, Y=Yn, mu_X=mu_X, sig_X=sig_X, mu_Y=mu_Y, sig_Y=sig_Y)\n",
    "print(f\"Saved NPZ → {OUT_NPZ}\")\n",
    "\n",
    "# Torch tensors\n",
    "X_t = torch.tensor(Xn)\n",
    "Y_t = torch.tensor(Yn)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(X_t, Y_t)\n",
    "loader  = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "net = DynNet()\n",
    "opt = optim.Adam(net.parameters(), 1e-3)\n",
    "\n",
    "print(\">>> Training …\")\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    running = 0.0\n",
    "    for xb, yb in loader:\n",
    "        pred = net(xb)\n",
    "        loss = ((pred - yb)**2).mean()\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        running += loss.item() * len(xb)\n",
    "    if epoch % 20 == 0 or epoch == 1:\n",
    "        mse = running / len(dataset)\n",
    "        print(f\"Epoch {epoch:3d}/{EPOCHS}   train‑MSE={mse:.4e}\")\n",
    "\n",
    "# Save\n",
    "ckpt = {\n",
    "    \"net\": net.state_dict(),\n",
    "    \"mu_X\": mu_X, \"sig_X\": sig_X,\n",
    "    \"mu_Y\": mu_Y, \"sig_Y\": sig_Y,\n",
    "    \"config\": dict(CSV_GLOB=CSV_GLOB, EPOCHS=EPOCHS,\n",
    "                    BATCH=BATCH_SIZE)\n",
    "}\n",
    "torch.save(ckpt, OUT_MODEL)\n",
    "print(f\"✓ Saved model → {OUT_MODEL}\\nDone.\")"
   ],
   "id": "761dd72f119c36d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Loading CSVs …\n",
      "Found 60 CSV files\n",
      ">>> Feature engineering …\n",
      "Dataset  X: (1921, 6),  Y: (1921, 4)\n",
      "Saved NPZ → model_dataset_v3.npz\n",
      ">>> Training …\n",
      "Epoch   1/300   train‑MSE=1.0136e+00\n",
      "Epoch  20/300   train‑MSE=7.8975e-01\n",
      "Epoch  40/300   train‑MSE=7.4797e-01\n",
      "Epoch  60/300   train‑MSE=7.2867e-01\n",
      "Epoch  80/300   train‑MSE=7.1322e-01\n",
      "Epoch 100/300   train‑MSE=6.9825e-01\n",
      "Epoch 120/300   train‑MSE=6.8302e-01\n",
      "Epoch 140/300   train‑MSE=6.6722e-01\n",
      "Epoch 160/300   train‑MSE=6.5092e-01\n",
      "Epoch 180/300   train‑MSE=6.3396e-01\n",
      "Epoch 200/300   train‑MSE=6.1643e-01\n",
      "Epoch 220/300   train‑MSE=5.9884e-01\n",
      "Epoch 240/300   train‑MSE=5.8253e-01\n",
      "Epoch 260/300   train‑MSE=5.6714e-01\n",
      "Epoch 280/300   train‑MSE=5.5296e-01\n",
      "Epoch 300/300   train‑MSE=5.3922e-01\n",
      "✓ Saved model → dyn_v3.pt\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96652e16119474e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
